---
title: "Loan Me Money?"
author: "Charles Westby"
date: "12/10/2017"
output: html_document
---

#Synopsis

#Exploratory Analysis
##Loading Data and Packages
```{r echo=TRUE, message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
library(ggplot2)
library(gridExtra)
library(caret)
library(VIM)

data <- read.csv("train-file.csv")
```

##Previewing The Data
###Structure of Data
```{r echo=TRUE, message=FALSE, warning=FALSE}
str(data)
```

###First Six Records
```{r echo=TRUE}
head(data)
```

###Summary of Data
```{r echo=TRUE}
summary(data)
```

###Tables
```{r echo=TRUE}
table(data$Loan_Amount_Term)
table(data$Credit_History)
```

When previewing this data, it shows that there are 614 records withs 13 different attributes. Some are factor variables and others are numeric or integers. The data also contains many missing values in its records. There are 13 missing values for Gender, 3 missing values for Married, 15 missing values for Dependents, 32 missing values for Self_Employed, 14 missing values for Loan_Amount_Term and 50 missing values for Credit_History. Of these records, 192 people were denied the loan and 422 were approved. 
Upon preview it was determined that Credit_History should be converted to a factor variable. This entry has only 1's, 0's and a few missing values. The 0 represents those who have not met the necessary guidelines for Credit History and 1 represents those who have.  

##Manipulating Data
###Creating Factor Variables
```{r echo=TRUE}
#Creating Factor Variables
data$Credit_History <- factor(data$Credit_History, labels = c("No", "Yes"))
```

###Subsetting Data
```{r echo=TRUE}
data_sub <- data %>%
  select(-Loan_ID)
```

###Imputing Missing Values
```{r echo=TRUE}
#Using kNN imputation
data_sub <- kNN(data_sub)

#Removing Variables Created by Imputation
data_sub <- data_sub %>%
  select(-(Gender_imp:Loan_Status_imp))
```

###New Summary
```{r echo=TRUE}
summary(data_sub)
```

###Visualizing the Data
```{r echo=TRUE, warning=FALSE, message=FALSE}
ggplot(data_sub, aes(x=ApplicantIncome, y = LoanAmount, col = Loan_Status)) +
  geom_jitter(alpha = 0.7) +
  facet_grid(. ~ Credit_History) +
  labs(title = "Loan Amount by Applicant Income and Credit History",
       x = "Applicant Income", y = "Loan Amount (Thousands)")

```

```{r echo=TRUE, warning=FALSE, message=FALSE}
ggplot(data_sub, aes(x=CoapplicantIncome, y = LoanAmount, col = Loan_Status)) +
  geom_jitter(alpha = 0.7) +
  facet_grid(. ~ Credit_History) + 
  labs(title = "Loan Amount by Coapplicant Income and Credit History",
       x = "Coapplicant Income", y = "Loan Amount (Thousands)")
```

```{r echo=TRUE, warning=FALSE, message=FALSE}
hist_loan <- ggplot(data_sub, aes(x=LoanAmount, fill=Loan_Status)) +
  geom_histogram() +
  labs(title="Histogram of Loan Amount by Loan Status",
       x="Loan Amount")
hist_income <- ggplot(data_sub, aes(x=ApplicantIncome, fill=Loan_Status)) +
  geom_histogram() +
  labs(title="Histogram of Applicant Income by Status",
       x = "Applicant Income")
grid.arrange(hist_loan, hist_income, nrow = 2)
```

###Further Investigation
####Poor Credit History But Approved
```{r echo=TRUE, warning=FALSE, message=FALSE}
#Finding Which Loans were approved and hadn't met credit history guidelines
poor_credit <- data_sub %>%
  filter(Loan_Status == "Y" & Credit_History == "No")
summary(poor_credit)
```

####Graphing Poor Credit
```{r echo=TRUE, warning=FALSE, message=FALSE}
ggplot(poor_credit, aes(x=ApplicantIncome, y = LoanAmount)) +
  geom_point() +
  labs(title = "Poor Credit but Approved", x= "Applicant Income",
       y= "Loan Amount (Thousands)")
```


Here the Loan_Amount_Term and Credit_History variables are turned into factor variables. Also the Loan_ID variable was removed because each record has a unique value here. In addition, the missing values for the data were imputed using kNN or k-Nearest Neighbor imputation. This imputation replaces the missing data with a value similar to other comparable records. 
When graphing the data, Credit History appears to be critical factor. In fact, after futher investigation, it is determined that there were only 8 out of 422 approvals for a loan, where the applicant's Credit History did not meet the guidelines. A deeper look at these 8 applicants shows that none were self-employed. Also most of these loans was less than $200,000. However one was for $600,000, but that applicant had an income of around $400,000. This analysis shows that Credit History is significant when deciding whether to approve or deny a loan.

#Machine Learning Models
##Partitioning The Data
```{r echo=TRUE}
set.seed(366284)
inTrain <- createDataPartition(y = data_sub$Loan_Status, p = 0.7, list=FALSE)
train <- data_sub[inTrain, ]
test <- data_sub[-inTrain, ]
```

##Random Forest Model
###Building Model
```{r echo=TRUE, warning=FALSE, message=FALSE}
model_rf <- train(Loan_Status ~ ., train, 
                  method = "ranger",
                  preProcess = c("center", "scale"),
                  tuneLength = 11, 
                  weights = as.numeric(train$Credit_History),
                  trControl = trainControl(method = "cv", 
                                           number = 10))
model_rf
```

###Testing Model
```{r echo=TRUE}
predictions_rf <- predict(model_rf, test)
confusionMatrix(predictions_rf, test$Loan_Status)
```

##Treebag Model
###Building Model
```{r echo=TRUE, message=FALSE, warning=FALSE}
model_bag <- train(Loan_Status ~ ., train, 
                  method = "treebag",
                  preProcess = c("center", "scale"),
                  tuneLength = 11, 
                  weights = as.numeric(train$Credit_History),
                  trControl = trainControl(method = "cv", 
                                           number = 10))
model_bag
```

###Testing Model
```{r echo=TRUE, warning=FALSE, message=FALSE}
predictions_bag <- predict(model_bag, test)
confusionMatrix(predictions_bag, test$Loan_Status)
```

#Conclusion
When building these models the train and the test sets were created using a 70/30 split of the original data. 70% of the data was randomly selected for the train set and the rest was selected for the test set. 
Next, the Random Forest Model was created using the `ranger` method in Caret. It ws preprocessed using centering and scaling. The tuneLength was adjusted to fit the number of predictors in the model. This adjustment lets the model test more models within, hopefully finding a more accurate model. Weight was added to the Credit_History variable, since this factor was one of the most important when determining Loan_Status. Finally, the model used ten-fold cross validation for resampling. 
After creating this model, the Treebag Model was created. This model was also preprocessed using centering and scaling. The tuneLength was adjusted to 11 too. Once again weight was added to the Credit History variable. And it also used ten-fold cross validation. 
When looking at both models, the Random Forest Model appears to perform better than the Treebag Model. The Random Forest Model picked a model that was about 79.33% accurate when tested internally. When this model was tested on the test set, it produced an accuracy that was 80.33% accurate. The Sensitivity or True Positive Rate was 49.12% and the Specificity or True Negative Rate was 94.44%. So this model was more accurate at picking those who would be approved for the loan, than it was at picking those who would be denied. The Treebag Model picked a model that was 74.71% when tested internally. When this Treebag Model was tested on the test set it was 74.86% accurate. The Sensitivity was 45.61% and the Specificity was 92.06%. This model was also more accurate when picking those who would be approved for the loan. As previously stated, the Random Forest Model will be the one that is used for the submissions.

#Submitting Results
```{r echo=TRUE}
final_test  <- read.csv("test-file.csv", header = TRUE)
final_test$Credit_History <- factor(final_test$Credit_History, labels = c("No", "Yes"))
final_test <- kNN(final_test)

#Removing Variables Created by Imputation
final_test <- final_test %>%
  select(-(Loan_ID_imp:Property_Area_imp))

predictions_rf <- predict(model_rf, final_test)
final_test$Loan_Status <- predictions_rf 


dim(final_test)

submission_rf <- final_test[, c("Loan_ID", "Loan_Status")]
write.csv(submission_rf, "loan_rf_predictions.csv", row.names = FALSE)

```